{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "747e9f84",
   "metadata": {},
   "source": [
    "# ðŸ“ˆ Predicting Project Outcomes from Evaluation Text\n",
    "\n",
    "In this third notebook, I implement a machine learning model using textual data extracted from project evaluations as predictors. The main objectives are:\n",
    "\n",
    "1. To compare the predictive performance of different sections of the evaluation text in estimating project outcome ratings.\n",
    "2. To identify the most relevant words or phrases (n-grams) that contribute to the model's predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989be1b1",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e62dc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import string\n",
    "import optuna\n",
    "import numpy as np\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import requests\n",
    "import pdfplumber \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from mord import OrdinalRidge  \n",
    "from sklearn.model_selection import train_test_split\n",
    "from io import BytesIO\n",
    "from tqdm import tqdm\n",
    "\n",
    "# determine working directories (notebook CWD)\n",
    "script_dir = os.getcwd()\n",
    "parent_dir = os.path.dirname(script_dir)\n",
    "data_dir = parent_dir + '\\\\1_Data'\n",
    "\n",
    "# Read data\n",
    "excel_file = os.path.join(data_dir, 'IEG_ICRR_PPAR_Ratings_2025-03-12.xlsx')\n",
    "df = pd.read_excel(excel_file)\n",
    "\n",
    "# Output directory:\n",
    "output = os.path.join(os.path.dirname(script_dir), '3_Outputs')\n",
    "output = \"C:\\\\Users\\\\wb592581\\\\Documents\\\\\"\n",
    "data_dir = r\"C:\\Users\\wb592581\\Documents\"\n",
    "\n",
    "# Filter the dataset to include only projects approved between 2015 to 2025 that are mapped to the Human Development Practice Group. \n",
    "df2 = df[\n",
    "    (df['Approval FY'] >= 2015) &\n",
    "    (df['Approval FY'] <= 2025) &\n",
    "    (df['Practice Group'] == 'HD')\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6f537d",
   "metadata": {},
   "source": [
    "## 2. Text Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1029edd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 328/328 [28:09<00:00,  5.15s/it]\n",
      "C:\\Users\\wb592581\\AppData\\Local\\Temp\\ipykernel_6368\\4063980361.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2['Full Text'] = df2['PDF'].progress_apply(extract_text_from_pdf)\n"
     ]
    }
   ],
   "source": [
    "# Extract full text from links\n",
    "tqdm.pandas()\n",
    "\n",
    "def extract_text_from_pdf(url):\n",
    "    try:\n",
    "        response = requests.get(url, timeout=15)\n",
    "        response.raise_for_status()\n",
    "        with pdfplumber.open(BytesIO(response.content)) as pdf:\n",
    "            text = ''.join(page.extract_text() or '' for page in pdf.pages)\n",
    "        return text.strip()\n",
    "    except Exception as e:\n",
    "        return f\"[ERROR] {e}\"\n",
    "\n",
    "df2['Full Text'] = df2['PDF'].progress_apply(extract_text_from_pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1aba4914",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wb592581\\AppData\\Local\\Temp\\ipykernel_6368\\1931054724.py:71: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2[['M&E Section', 'M&E: Design', 'M&E: Implementation', 'M&E: Utilization', 'Outcome_section']] = df2.apply(extract_sections, axis=1)\n",
      "C:\\Users\\wb592581\\AppData\\Local\\Temp\\ipykernel_6368\\1931054724.py:71: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2[['M&E Section', 'M&E: Design', 'M&E: Implementation', 'M&E: Utilization', 'Outcome_section']] = df2.apply(extract_sections, axis=1)\n",
      "C:\\Users\\wb592581\\AppData\\Local\\Temp\\ipykernel_6368\\1931054724.py:71: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2[['M&E Section', 'M&E: Design', 'M&E: Implementation', 'M&E: Utilization', 'Outcome_section']] = df2.apply(extract_sections, axis=1)\n",
      "C:\\Users\\wb592581\\AppData\\Local\\Temp\\ipykernel_6368\\1931054724.py:71: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2[['M&E Section', 'M&E: Design', 'M&E: Implementation', 'M&E: Utilization', 'Outcome_section']] = df2.apply(extract_sections, axis=1)\n",
      "C:\\Users\\wb592581\\AppData\\Local\\Temp\\ipykernel_6368\\1931054724.py:71: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2[['M&E Section', 'M&E: Design', 'M&E: Implementation', 'M&E: Utilization', 'Outcome_section']] = df2.apply(extract_sections, axis=1)\n",
      "C:\\Users\\wb592581\\AppData\\Local\\Temp\\ipykernel_6368\\1931054724.py:80: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2['outcome_score'] = df2['IEG Outcome Ratings'].map(rating_mapping)\n",
      "C:\\Users\\wb592581\\AppData\\Local\\Temp\\ipykernel_6368\\1931054724.py:81: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2.drop(columns=['IEG Outcome Ratings'], inplace=True, errors='ignore')\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# Function to extract sections from full project evaluations\n",
    "# ----------------------------\n",
    "def extract_section(text, start_pattern, end_pattern, label):\n",
    "    # Compile regex patterns (case insensitive)\n",
    "    start_regex = re.compile(rf\"{start_pattern}\", re.IGNORECASE)\n",
    "    end_regex = re.compile(rf\"{end_pattern}\", re.IGNORECASE)\n",
    "\n",
    "    # Split text into lines\n",
    "    lines = text.splitlines()\n",
    "    start_idx = end_idx = None\n",
    "\n",
    "    # Identify the index range between start and end patterns\n",
    "    for i, line in enumerate(lines):\n",
    "        if start_idx is None and start_regex.search(line.strip()):\n",
    "            start_idx = i\n",
    "        elif start_idx is not None and end_regex.search(line.strip()):\n",
    "            end_idx = i\n",
    "            break\n",
    "\n",
    "    # Return the section if both indices are found and valid\n",
    "    if start_idx is not None and end_idx is not None and end_idx > start_idx:\n",
    "        return \"\\n\".join(lines[start_idx:end_idx+1])\n",
    "    else:\n",
    "        return \"\"\n",
    "\n",
    "# ----------------------------\n",
    "# Apply section extraction to each row\n",
    "# ----------------------------\n",
    "def extract_sections(row):\n",
    "    text = row['Full Text']\n",
    "    me_section = extract_section(\n",
    "        text,\n",
    "        start_pattern=r\"\\bM&E\\s+Design.*Utilization\\b\", \n",
    "        end_pattern=r\"\\bM&E\\s+Quality\\s+Rating\\b\", \n",
    "        label=\"M&E Section\"\n",
    "    )\n",
    "    me_design = extract_section(\n",
    "        text,\n",
    "        start_pattern=r\"\\bM&E\\s+Design\\b\", \n",
    "        end_pattern=r\"\\bM&E\\s+Implementation\\b\", \n",
    "        label=\"M&E: Design\"\n",
    "    )\n",
    "    me_implementation = extract_section(\n",
    "        text,\n",
    "        start_pattern=r\"\\bM&E\\s+Implementation\\b\", \n",
    "        end_pattern=r\"\\bM&E\\s+Utilization\\b\", \n",
    "        label=\"M&E: Implementation\"\n",
    "    )\n",
    "    me_utilization = extract_section(\n",
    "        text,\n",
    "        start_pattern=r\"\\bM&E\\s+Utilization\\b\", \n",
    "        end_pattern=r\"\\bM&E\\s+Quality\\s+Rating\\b\", \n",
    "        label=\"M&E: Utilization\"\n",
    "    )\n",
    "    outcome_section = extract_section(\n",
    "        text,\n",
    "        start_pattern=r'[567][\\.\\)]?\\s*Outcome\\b.*',\n",
    "        end_pattern=r'(IEG\\s+)?Outcome\\s+Rating\\b.*',\n",
    "        label=\"Outcome Section\"\n",
    "    )\n",
    "    return pd.Series({\n",
    "        'M&E Section': me_section,\n",
    "        'M&E: Design': me_design,\n",
    "        'M&E: Implementation': me_implementation,\n",
    "        'M&E: Utilization': me_utilization,\n",
    "        'Outcome_section': outcome_section\n",
    "    })\n",
    "\n",
    "# Apply extraction to the DataFrame\n",
    "df2[['M&E Section', 'M&E: Design', 'M&E: Implementation', 'M&E: Utilization', 'Outcome_section']] = df2.apply(extract_sections, axis=1)\n",
    "\n",
    "# ----------------------------\n",
    "# Convert outcome ratings to numeric scores\n",
    "# ----------------------------\n",
    "rating_mapping = {\n",
    "    'Highly Unsatisfactory': 1, 'Unsatisfactory': 2, 'Moderately Unsatisfactory': 3,\n",
    "    'Moderately Satisfactory': 4, 'Satisfactory': 5, 'Highly Satisfactory': 6\n",
    "}\n",
    "df2['outcome_score'] = df2['IEG Outcome Ratings'].map(rating_mapping)\n",
    "df2.drop(columns=['IEG Outcome Ratings'], inplace=True, errors='ignore')\n",
    "\n",
    "# ----------------------------\n",
    "# Custom words to remove from text\n",
    "# ----------------------------\n",
    "custom_stopwords = set([\n",
    "    \"pbf\", \"ndc\", \"eur\", \"rating\", \"icr\", \"outcome\",\n",
    "    \"unsatisfactory\", \"satisfactory\", \"moderately\", \"highly\",\n",
    "    \"monitoring\", \"design\", \"implementation\", \"utilization\",\n",
    "    \"lesson\", \"evaluation\", \"modest\", \"bme\", \"cme\", \"dlis\", \"high\", \n",
    "    \"efficiency\", \"negligible\", \"substantial\", \"lessons\", \"ppmp\", \"piu\",\n",
    "    \"indicators\", \"independent\", \"group\"\n",
    "])\n",
    "\n",
    "# ----------------------------\n",
    "# Function to clean text for modeling\n",
    "# ----------------------------\n",
    "def clean_text(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r'\\d+', '', text)  # Remove numbers\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))  # Remove punctuation\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  # Normalize spaces\n",
    "\n",
    "    # Remove full-word stopwords\n",
    "    pattern = r'\\b(?:' + '|'.join(re.escape(word) for word in custom_stopwords) + r')\\b'\n",
    "    text = re.sub(pattern, '', text)\n",
    "\n",
    "    # Final cleanup\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "# ----------------------------\n",
    "# Apply text cleaning to selected text fields\n",
    "# ----------------------------\n",
    "text_vars = ['Full Text', 'M&E Section', 'M&E: Design', 'M&E: Implementation', 'M&E: Utilization', 'Lesson']\n",
    "df2_cleaned = df2.copy()\n",
    "for var in text_vars:\n",
    "    df2_cleaned[var] = df2_cleaned[var].fillna(\"\").apply(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c5429d",
   "metadata": {},
   "source": [
    "## 3. ML Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing text variable: Full Text\n"
     ]
    }
   ],
   "source": [
    "# Dictionary to store results\n",
    "results = {}\n",
    "N_TRIALS = 15  # Number of optimization trials\n",
    "\n",
    "# Loop over each text variable\n",
    "for var in text_vars:\n",
    "    print(f\"\\nProcessing text variable: {var}\")\n",
    "    \n",
    "    # TF-IDF vectorization with 1- to 3-grams\n",
    "    tfidf = TfidfVectorizer(ngram_range=(1, 3), max_features=5000, stop_words='english')\n",
    "    X_tfidf = tfidf.fit_transform(df2_cleaned[var])\n",
    "    y = df2_cleaned[\"outcome_score\"].astype(int)\n",
    "\n",
    "    # Train/test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    model_results = {}\n",
    "\n",
    "    # ------------------ LightGBM ------------------\n",
    "    def objective_lgbm(trial):\n",
    "        params = {\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 100, 500),\n",
    "            'max_depth': trial.suggest_int('max_depth', 3, 12),\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 1e-3, 0.2, log=True)\n",
    "        }\n",
    "        model = LGBMRegressor(**params)\n",
    "        model.fit(X_train, y_train)\n",
    "        preds = model.predict(X_test)\n",
    "        return mean_squared_error(y_test, preds, squared=False)  # RMSE\n",
    "\n",
    "    study_lgbm = optuna.create_study(direction='minimize')\n",
    "    study_lgbm.optimize(objective_lgbm, n_trials=N_TRIALS)\n",
    "\n",
    "    best_lgbm = LGBMRegressor(**study_lgbm.best_params)\n",
    "    best_lgbm.fit(X_train, y_train)\n",
    "    model_results['lgbm'] = (best_lgbm, tfidf)\n",
    "\n",
    "    # ------------------ Random Forest ------------------\n",
    "    def objective_rf(trial):\n",
    "        params = {\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 100, 500),\n",
    "            'max_depth': trial.suggest_int('max_depth', 3, 15)\n",
    "        }\n",
    "        model = RandomForestRegressor(**params)\n",
    "        model.fit(X_train, y_train)\n",
    "        preds = model.predict(X_test)\n",
    "        return mean_squared_error(y_test, preds, squared=False)  # RMSE\n",
    "\n",
    "    study_rf = optuna.create_study(direction='minimize')\n",
    "    study_rf.optimize(objective_rf, n_trials=N_TRIALS)\n",
    "\n",
    "    best_rf = RandomForestRegressor(**study_rf.best_params)\n",
    "    best_rf.fit(X_train, y_train)\n",
    "    model_results['rf'] = (best_rf, tfidf)\n",
    "\n",
    "    # ------------------ Ordinal Regression ------------------\n",
    "    model_ordinal = OrdinalRidge()\n",
    "    model_ordinal.fit(X_train, y_train)\n",
    "    model_results['ordinal'] = (model_ordinal, tfidf)\n",
    "\n",
    "    # Save models and vectorizer to pickle files\n",
    "    for model_name, (model, vec) in model_results.items():\n",
    "        filename = os.path.join(data_dir, f\"model_{model_name}_{var}.pkl\")\n",
    "        with open(filename, 'wb') as f:\n",
    "            pickle.dump({'model': model, 'vectorizer': vec}, f)\n",
    "\n",
    "    # Store results in dictionary\n",
    "    results[var] = model_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9790693",
   "metadata": {},
   "source": [
    "## 3. Evaluation Metrics and Variable Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_dict = {'lgbm': [], 'rf': [], 'ordinal': []}\n",
    "labels = ['Full Text', 'M&E Section', 'M&E: Design', 'M&E: Implementation', 'M&E: Utilization', 'Lesson']\n",
    "\n",
    "for model_type in ['lgbm', 'rf', 'ordinal']:\n",
    "    for var in text_vars:\n",
    "        filename = os.path.join(data_dir, f\"model_{model_type}_{var}.pkl\")\n",
    "        with open(filename, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "\n",
    "        model = data['model']\n",
    "        vec = data['vectorizer']\n",
    "\n",
    "        X_all = vec.transform(df2_cleaned[var])\n",
    "        y_all = df2_cleaned[\"outcome_score\"].astype(int)\n",
    "        _, X_test, _, y_test = train_test_split(X_all, y_all, test_size=0.2, random_state=42)\n",
    "\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "        metrics_dict[model_type].append({'RMSE': rmse, 'MSE': mse, 'MAE': mae})\n",
    "\n",
    "# Graph\n",
    "for model_type in ['lgbm', 'rf', 'ordinal']:\n",
    "    df_metric = pd.DataFrame(metrics_dict[model_type], index=labels)\n",
    "    df_metric = df_metric[['RMSE', 'MSE', 'MAE']]  # Ordenar columnas\n",
    "    df_metric.plot(kind='bar', figsize=(10, 5), title=f'{model_type.upper()} - Test Set Prediction Errors')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.ylabel(\"Error\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f57a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable Importance\n",
    "for model_type in ['lgbm', 'rf', 'ordinal']:\n",
    "    fig, axes = plt.subplots(1, 6, figsize=(20, 8))\n",
    "    fig.suptitle(f\"Top 10 n-grams por modelo - {model_type.upper()}\")\n",
    "    \n",
    "    for i, var in enumerate(text_vars):\n",
    "        filename = os.path.join(dir2, f\"model_{model_type}_{var}.pkl\")\n",
    "        with open(filename, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        model, vec = data['model'], data['vectorizer']\n",
    "        \n",
    "        if model_type == 'ordinal':\n",
    "            importances = np.abs(model.coef_).flatten()\n",
    "        else:\n",
    "            importances = model.feature_importances_\n",
    "\n",
    "        features = np.array(vec.get_feature_names_out())\n",
    "        idx = np.argsort(importances)[-10:][::-1]\n",
    "        \n",
    "        axes[i].barh(features[idx], importances[idx])\n",
    "        axes[i].set_title(var)\n",
    "        axes[i].invert_yaxis()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b526b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c01039",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
